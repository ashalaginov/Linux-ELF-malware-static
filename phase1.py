print ("Phase 1")

malwareDir="ELF/"

import mysql.connector
from mysql.connector import Error
from mysql.connector import errorcode
import os
import hashlib
import json
import subprocess
import timeit

# MD5 calculation
def md5(fname):
    hash_md5 = hashlib.md5()
    with open(fname, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()


# Retrieving all raw files from the ELF/ directory to be processed
arr = os.listdir(malwareDir)
num_files=len(arr)
print("Number of files: "+str(num_files))


# Process files and insert into MySQL database
print("Batch processing started")
i=0
count=0
query_array=[]
start = timeit.default_timer()

for file in arr:
    i+=1 
    count+=1
    query=();

    # Full path
    filename=malwareDir+file

    if str(os.popen('readelf -h '+filename).read()).find("ELF")>=0:
	    # MD5    
	    query+=(str(md5(filename)),)

	    # Peframe
	    tmp_peframe=(os.popen('peframe -j '+filename).read(),)
	    query+=tmp_peframe

	    # Readelf
	    query+=(str(os.popen('readelf -h '+filename).read()),)
	    
	    # 'file' command
	    query+=(str(os.popen('file -b '+filename).read()),)
	    
	    # 'strings' command
	    query+=(str(os.popen('strings '+filename).read()),)

	    # filesize
	    query+=(str(os.path.getsize(filename)),)
	    
	    # Shannon Entropy  - ent tool
	    query+=(str(os.popen("ent "+filename+" | head -n 1 |  awk '{print $(NF-3)}'").read().strip()),)
	    
	    # md5 on duplicate
	    query+=(str(md5(filename)),)
	    
	    # peframe on duplicate
	    query+=tmp_peframe

	    query_array.append(query);
	    # Stack data to be places into mysql
	    if(count % 10 == 0):
	    
	    # Connect to MySQL server
		connection = mysql.connector.connect(host='localhost',
		                                    database='ELF',
		                                    user='ELF',
		                                    password='toor')
		cursor = connection.cursor(buffered=True)
		    
		sql = "INSERT IGNORE INTO rawData (md5,  peframe, readelf, file, strings, size, file_entropy) VALUES (%s, %s, %s, %s, %s, %s, %s) ON DUPLICATE KEY UPDATE md5=%s, peframe=%s"
		cursor.executemany(sql, query_array)

		connection.commit()
	    
		print(cursor.rowcount, "Transaction sucessfull")
	    
		cursor.close()
		connection.close()

		print "Processed "+str(i)+" - "+str(round(float(i)/num_files*100,2))+"% out of "+str(num_files) 

		stop = timeit.default_timer()
		print "Time: "+ str(round(stop - start,2))+" seconds"
		start = timeit.default_timer()
		count=0
	    	query_array=[]

	    print i
    else:
	    print("Not ELF...deleting")
	    print(os.popen('rm '+filename).read())
